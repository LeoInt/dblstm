#include "layer.h"
#define impl 2
// 1 basic, 2 fused
#define cudaErrCheck(stat) { cudaErrCheck_((stat), __FILE__, __LINE__); }
static void cudaErrCheck_(cudaError_t stat, const char *file, int line) {
  if (stat != cudaSuccess) {
    fprintf(stderr, "CUDA Error: %s %s %d\n", cudaGetErrorString(stat), file, line);
  }
}

#define cublasErrCheck(stat) { cublasErrCheck_((stat), __FILE__, __LINE__); }
static void cublasErrCheck_(cublasStatus_t stat, const char *file, int line) {
  if (stat != CUBLAS_STATUS_SUCCESS) {
    fprintf(stderr, "cuBLAS Error: %d %s %d\n", stat, file, line);
  }
}

#define curandErrCheck(stat) { curandErrCheck_((stat), __FILE__, __LINE__); }
static void curandErrCheck_(curandStatus_t stat, const char *file, int line) {
  if (stat != CURAND_STATUS_SUCCESS) {
    fprintf(stderr, "cuRand Error: %d %s %d\n", stat, file, line);
  }
}


static  void Print_matrix(float* mat, int n, int m, int r_c){
    //const char nmfile[] = "out.txt";
    float *data_host;
    data_host=(float*)malloc(n*m*sizeof(float));
    cudaMemcpy(data_host, mat, n*m*sizeof(float), cudaMemcpyDeviceToHost);  // this won't work, will throw error
    if(r_c==0){
      for (int jj=0; jj<n; jj++)
      {
        int ii;
        for (ii=0; ii<m; ii++)
        {
          float* temp=(float *)(data_host+jj*m+ii);
          printf("%.10e ", *temp);
                  //if(jj==101) printf("%f ", *temp);
        }
        printf("\n");
      }
    }else{
      for (int jj=0; jj<n; jj++)
      {
        int ii;
        for (ii=0; ii<m; ii++)
        {
          float* temp=(float *)(data_host+ii*n+jj);
          printf("%.10e ", *temp);
                    //if(jj==101) printf("%f ", *temp);
        }
        printf("\n");
      }
    }
    free(data_host);
  }

 Layer::Layer(int input_dim, int output_dim, int cell_dim) { 
      input_dim_= input_dim; // 640
      output_dim_= output_dim; //640
      cell_dim_ = cell_dim; //320
        //cuda malloc
  
  cudaErrCheck(cudaMalloc((void**)&wei_gifo_x_fw_,  input_dim_  * 4 * cell_dim_ * sizeof(float)));
  cudaErrCheck(cudaMalloc((void**)&wei_gifo_m_fw_, 2*( cell_dim_  * 4 * cell_dim_ * sizeof(float)))); //ch
  cudaErrCheck(cudaMalloc((void**)&bias_fw_, 4 * cell_dim_ * sizeof(float)));
  cudaErrCheck(cudaMalloc((void**)&phole_o_c_fw_, 2*cell_dim_ * sizeof(float))); //ch
  cudaErrCheck(cudaMalloc((void**)&phole_i_c_fw_, 2*cell_dim_ * sizeof(float))); //ch
  cudaErrCheck(cudaMalloc((void**)&phole_f_c_fw_, 2*cell_dim_ * sizeof(float))); //ch

  cudaErrCheck(cudaMalloc((void**)&wei_gifo_x_bw_,  input_dim_  * 4 * cell_dim_ * sizeof(float)));
  cudaErrCheck(cudaMalloc((void**)&wei_gifo_m_bw_,  cell_dim_  * 4 * cell_dim_ * sizeof(float)));
  cudaErrCheck(cudaMalloc((void**)&bias_bw_, 4 * cell_dim_ * sizeof(float)));
  cudaErrCheck(cudaMalloc((void**)&phole_o_c_bw_, cell_dim_ * sizeof(float)));
  cudaErrCheck(cudaMalloc((void**)&phole_i_c_bw_,cell_dim_ * sizeof(float)));
  cudaErrCheck(cudaMalloc((void**)&phole_f_c_bw_, cell_dim_ * sizeof(float)));
    }
  Layer::~Layer(){
  
  cudaErrCheck(cudaFree(wei_gifo_x_fw_));
  cudaErrCheck(cudaFree(wei_gifo_m_fw_));
  cudaErrCheck(cudaFree(wei_gifo_x_bw_));
  cudaErrCheck(cudaFree(wei_gifo_m_bw_));
  cudaErrCheck(cudaFree(bias_fw_));
  cudaErrCheck(cudaFree(bias_bw_));
  cudaErrCheck(cudaFree(phole_o_c_fw_));
  cudaErrCheck(cudaFree(phole_i_c_fw_));
  cudaErrCheck(cudaFree(phole_f_c_fw_));
  cudaErrCheck(cudaFree(phole_o_c_bw_));
  cudaErrCheck(cudaFree(phole_i_c_bw_));
  cudaErrCheck(cudaFree(phole_f_c_bw_));
  
  } 
#if impl==1 
  float Layer::Propagate(cublasHandle_t handle, float* in, float* out, int seqLength, float* tmp_h_fw, float* tmp_i_fw, float* tmp_h_bw, float* tmp_i_bw, float* h_data, float* c_data, float* h_data_bw, float* c_data_bw){
      //continue
  dim3 blockDim, gridDim;
  cudaStream_t stream=NULL;
  float alpha = 1.f;
  float beta  = 0.f;
  int frame;
  cudaEvent_t start, stop;
  float elapsedTime=0.f;
  
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord(start);

  const cublasOperation_t transa = CUBLAS_OP_N;
  const cublasOperation_t transb = CUBLAS_OP_N;
  cudaMemset(h_data, 0, cell_dim_*sizeof(float));
  cudaMemset(c_data, 0, cell_dim_*sizeof(float));
  cudaMemset(h_data_bw , 0, cell_dim_*sizeof(float));
  cudaMemset(c_data_bw , 0, cell_dim_*sizeof(float));

  
  
  cublasErrCheck(cublasSgemm(handle,
                        transa, transb,
                        4 * cell_dim_, //m, number of rows of matrix op(A) and C.
                        seqLength , //n, number of cols of matrix op(B) and C.
                        input_dim_,  //k, number of cols of matrix op(A) and rows of op(B).
                        &alpha,
                        wei_gifo_x_fw_,
                        transa == CUBLAS_OP_N ? 4 * cell_dim_ : input_dim_,  //leading dimension = number of rows (I use the number of col because I do the transpose with transa)
                        in,
                        input_dim_,
                        &beta,
                        tmp_i_fw,
                        4 * cell_dim_));
  for (frame=0; frame < seqLength ; frame ++){
         cublasErrCheck(cublasSgemv(handle, transa,
               4 * cell_dim_, //m, number of rows of matrix op(A) 
               cell_dim_, //n, number of cols of matrix op(A).
               &alpha,
               wei_gifo_m_fw_, 
               4 * cell_dim_,
               h_data + (frame%2) * cell_dim_, 
               1, //stride input array
               &beta,
               tmp_h_fw, 
               1)); //stide output array
           //this procedure using matrix ve product also works but it is tricky to set parameters, the matrix dim is lda x n (instead of beinf lda x m) so m and n are inverted and the transpose is applied thanks to the flag
   /*cublasErrCheck(cublasSgemm(handle,
    transa, transb,
    4 * cell_dim_, //m, number of rows of matrix op(A) and C.
    1 , //n, number of cols of matrix op(B) and C.
    cell_dim_,  //k, number of cols of matrix op(A) and rows of op(B).
    &alpha,
    wei_gifo_m_fw_,
    transa == CUBLAS_OP_N ? 4 * cell_dim_ : cell_dim_,  //leading dimension = number of rows (I use the number of col because I do the transpose with transa)
    h_data + frame * cell_dim_,
    cell_dim_,
    &beta,
    tmp_h_fw,
    4 * cell_dim_)); //in this case the matrix is lda x k with if transa == CUBLAS_OP_N and lda x m if transa == CUBLAS_OP_T
         */
    //Print_matrix(h_data + frame * cell_dim_, cell_dim_,1,1);
    //printf("\n");
    
    stream=NULL;
    blockDim.x = 128;
    gridDim.x = (cell_dim_ + blockDim.x - 1) / blockDim.x;
    
    for (int i = 0; i < 4; i++) {
      if (tmp_h_fw != NULL) {
      pw_vecAdd_w(gridDim, blockDim, stream, tmp_i_fw + i * cell_dim_ + 4 * frame * cell_dim_, tmp_i_fw + i * cell_dim_ + 4 * frame * cell_dim_, tmp_h_fw  + i * cell_dim_, cell_dim_);
      cudaErrCheck(cudaGetLastError());
               //gifo(t)=sigma(Wx*X_t+Wm*M_(t-1)+b) ()
      }
      pw_biasAdd_w(gridDim, blockDim, stream, tmp_i_fw + i * cell_dim_ + 4 * frame * cell_dim_, bias_fw_ + i       * cell_dim_ ,  cell_dim_, cell_dim_);
      cudaErrCheck(cudaGetLastError());
               //gifo(t)=sigma(Wx*X_t+Wm*M_(t-1)+b) (add Wx bias)

      //pw_biasAdd <<< gridDim, blockDim, 0, stream >>> (tmp_i + i * numElements + 4 * frame * numElements, bias + (i + 4) * hiddenSize + layer * hiddenSize * 8, numElements, hiddenSize);
      //cudaErrCheck(cudaGetLastError());
               //gifo(t)=sigma(Wx*X_t+Wm*M_(t-1)+b) (add Wm bias)
    }
    
    //Print_matrix(tmp_i_fw + 4 * frame * cell_dim_, 4*cell_dim_,1,1);
    //printf("\n");
    add_pw_vecMul_w(gridDim, blockDim, stream, tmp_i_fw + 1 * cell_dim_ + 4 * frame * cell_dim_, c_data + (frame%2) * cell_dim_ , phole_i_c_fw_ , cell_dim_);
    cudaErrCheck(cudaGetLastError());
    add_pw_vecMul_w(gridDim, blockDim, stream, tmp_i_fw + 2 * cell_dim_ + 4 * frame * cell_dim_, c_data + (frame%2) * cell_dim_ , phole_f_c_fw_ , cell_dim_);
    cudaErrCheck(cudaGetLastError());
    

    pw_tanh_w(gridDim, blockDim, stream, tmp_i_fw + 0 * cell_dim_ + 4 * frame * cell_dim_, tmp_i_fw + 0 * cell_dim_ + 4 * frame * cell_dim_, cell_dim_);
    cudaErrCheck(cudaGetLastError());
            //in gate 2 ... also known as g 
    pw_sigmoid_w(gridDim, blockDim, stream, tmp_i_fw + 1 * cell_dim_ + 4 * frame * cell_dim_, tmp_i_fw + 1 * cell_dim_ + 4 * frame * cell_dim_, cell_dim_);
    cudaErrCheck(cudaGetLastError());
            //input gate
    pw_sigmoid_w(gridDim, blockDim, stream, tmp_i_fw + 2 * cell_dim_ + 4 * frame * cell_dim_, tmp_i_fw + 2 * cell_dim_ + 4 * frame * cell_dim_, cell_dim_);
    cudaErrCheck(cudaGetLastError());
            //forget gate
 
            //output gate
         //Print_matrix_to_file("foret.txt", tmp_i + 1 * numElements + 4 * frame * numElements, hiddenSize, 1, 1);
         //Print_matrix_to_file("in_gate2.txt", tmp_i + 2 * numElements + 4 * frame * numElements, hiddenSize, 1, 1);
         //Print_matrix_to_file("outgate.txt", tmp_i + 3 * numElements + 4 * frame * numElements, hiddenSize, 1, 1);

    
    float *in_gate2    = tmp_i_fw + 0 * cell_dim_ + 4 * frame * cell_dim_;
    float *in_gate     = tmp_i_fw + 1 * cell_dim_ + 4 * frame * cell_dim_;
    float *forget_gate = tmp_i_fw + 2 * cell_dim_ + 4 * frame * cell_dim_;
    float *out_gate    = tmp_i_fw + 3 * cell_dim_ + 4 * frame * cell_dim_;
    float *c_in        = c_data + (frame%2) * cell_dim_;
    float* c_out;

    c_out       = c_data + ((frame + 1)%2) * cell_dim_ ;

    if (c_in == NULL) {
      pw_vecMul_w(gridDim, blockDim, stream, in_gate, in_gate, in_gate2, cell_dim_);
      cudaErrCheck(cudaGetLastError());
    }
    else {              
      pw_vecMul_w(gridDim, blockDim, stream, forget_gate, forget_gate, c_in, cell_dim_);
      cudaErrCheck(cudaGetLastError());

      pw_vecMul_w(gridDim, blockDim, stream, in_gate, in_gate, in_gate2, cell_dim_);
      cudaErrCheck(cudaGetLastError());

      pw_vecAdd_w(gridDim, blockDim, stream, in_gate, in_gate, forget_gate, cell_dim_); //c_out computed
      cudaErrCheck(cudaGetLastError());
    }

   
    add_pw_vecMul_w( gridDim, blockDim, stream, out_gate, in_gate, phole_o_c_fw_ , cell_dim_); //out=out+c*p_hole
    cudaErrCheck(cudaGetLastError());

    pw_sigmoid_w(gridDim, blockDim, stream, out_gate, out_gate, cell_dim_);
    cudaErrCheck(cudaGetLastError());
 

    if (c_out != NULL) {
      cudaErrCheck(cudaMemcpyAsync(c_out, in_gate, cell_dim_ * sizeof(float), cudaMemcpyDeviceToDevice, stream));
    }

    pw_tanh_w(gridDim, blockDim, stream, in_gate, in_gate, cell_dim_);
    cudaErrCheck(cudaGetLastError());

    pw_vecMul_w(gridDim, blockDim, stream, h_data + ((frame+1)%2) * cell_dim_ , out_gate, in_gate, cell_dim_);
    cudaErrCheck(cudaGetLastError());

    pw_vecMul_w(gridDim, blockDim, stream, out + frame * 2* cell_dim_ , out_gate, in_gate, cell_dim_);
    cudaErrCheck(cudaGetLastError());

    }//frame loop





////backward//////////////////////////////////////////////////////////////////////
  cublasErrCheck(cublasSgemm(handle,
                        transa, transb,
                        4 * cell_dim_, //m, number of rows of matrix op(A) and C.
                        seqLength , //n, number of cols of matrix op(B) and C.
                        input_dim_,  //k, number of cols of matrix op(A) and rows of op(B).
                        &alpha,
                        wei_gifo_x_bw_,
                        transa == CUBLAS_OP_N ? 4*cell_dim_ : input_dim_,  //leading dimension = number of rows (I use the number of col because I do the transpose with transa)
                        in,
                        input_dim_,
                        &beta,
                        tmp_i_bw,
                        4 * cell_dim_));
  for (frame=seqLength-1; frame >=0 ; frame --){
         cublasErrCheck(cublasSgemv(handle, transa,
               4*cell_dim_, //m, number of rows of matrix op(A) 
               cell_dim_, //n, number of cols of matrix op(A).
               &alpha,
               wei_gifo_m_bw_, 
               4*cell_dim_,
               h_data_bw + ((frame+1)%2) * cell_dim_, 
               1, //stride input array
               &beta,
               tmp_h_bw, 
               1)); //stide output array
           //this procedure using matrix ve product also works but it is tricky to set parameters, the matrix dim is lda x n (instead of beinf lda x m) so m and n are inverted and the transpose is applied thanks to the flag
   /*cublasErrCheck(cublasSgemm(handle,
    transa, transb,
    4 * cell_dim_, //m, number of rows of matrix op(A) and C.
    1 , //n, number of cols of matrix op(B) and C.
    cell_dim_,  //k, number of cols of matrix op(A) and rows of op(B).
    &alpha,
    wei_gifo_m_bw_,
    transa == CUBLAS_OP_N ? 4 * cell_dim_ : cell_dim_,  //leading dimension = number of rows (I use the number of col because I do the transpose with transa)
    h_data_bw + (frame+1) * cell_dim_,
    cell_dim_,
    &beta,
    tmp_h_bw,
    4 * cell_dim_)); //in this case the matrix is lda x k with if transa == CUBLAS_OP_N and lda x m if transa == CUBLAS_OP_T
         */
  //cudaStream_t stream=stream_h[layer];
    cudaStream_t stream=NULL;
    blockDim.x = 128;
    gridDim.x = (cell_dim_ + blockDim.x - 1) / blockDim.x;
         //Print_matrix_to_file("tmp_h.txt", tmp_h, 4*hiddenSize, 1, 1);
  
    for (int i = 0; i < 4; i++) {
      if (tmp_h_bw != NULL) {
        pw_vecAdd_w(gridDim, blockDim, stream, tmp_i_bw + i * cell_dim_ + 4 * frame * cell_dim_, tmp_i_bw + i * cell_dim_ + 4 * frame * cell_dim_, tmp_h_bw  + i * cell_dim_, cell_dim_);
        cudaErrCheck(cudaGetLastError());
               //gifo(t)=sigma(Wx*X_t+Wm*M_(t-1)+b) ()
    }
    pw_biasAdd_w(gridDim, blockDim, stream, tmp_i_bw + i * cell_dim_ + 4 * frame * cell_dim_, bias_bw_ + i       * cell_dim_ , cell_dim_, cell_dim_);
    cudaErrCheck(cudaGetLastError());
               //gifo(t)=sigma(Wx*X_t+Wm*M_(t-1)+b) (add Wx bias)

    //pw_biasAdd <<< gridDim, blockDim, 0, stream >>> (tmp_i_bw + i * cell_dim_ + 4 * frame * cell_dim_, bias_bw + (i + 4) * cell_dim_ + layer * cell_dim_ * 8, cell_dim_, cell_dim_);
    //cudaErrCheck(cudaGetLastError());
               //gifo(t)=sigma(Wx*X_t+Wm*M_(t-1)+b) (add Wm bias)
  }
   
  add_pw_vecMul_w(gridDim, blockDim, stream, tmp_i_bw + 1 * cell_dim_ + 4 * frame * cell_dim_, c_data_bw + ((frame+1)%2) * cell_dim_ , phole_i_c_bw_ , cell_dim_);
  cudaErrCheck(cudaGetLastError());
  add_pw_vecMul_w(gridDim, blockDim, stream, tmp_i_bw + 2 * cell_dim_ + 4 * frame * cell_dim_, c_data_bw + ((frame+1)%2) * cell_dim_ , phole_f_c_bw_ , cell_dim_);
  cudaErrCheck(cudaGetLastError());

  pw_tanh_w (gridDim, blockDim, stream, tmp_i_bw + 0 * cell_dim_ + 4 * frame * cell_dim_, tmp_i_bw + 0 * cell_dim_ + 4 * frame * cell_dim_, cell_dim_);
  cudaErrCheck(cudaGetLastError());
            //in gate 2

  pw_sigmoid_w(gridDim, blockDim, stream, tmp_i_bw + 1 * cell_dim_ + 4 * frame * cell_dim_, tmp_i_bw + 1 * cell_dim_ + 4 * frame * cell_dim_, cell_dim_);
  cudaErrCheck(cudaGetLastError());
            //input gate

  pw_sigmoid_w(gridDim, blockDim, stream, tmp_i_bw + 2 * cell_dim_ + 4 * frame * cell_dim_, tmp_i_bw + 2 * cell_dim_ + 4 * frame * cell_dim_, cell_dim_);
  cudaErrCheck(cudaGetLastError());
            //forget gate

  float *in_gate2    = tmp_i_bw + 0 * cell_dim_ + 4 * frame * cell_dim_;
  float *in_gate     = tmp_i_bw + 1 * cell_dim_ + 4 * frame * cell_dim_;
  float *forget_gate = tmp_i_bw + 2 * cell_dim_ + 4 * frame * cell_dim_;
  float *out_gate    = tmp_i_bw + 3 * cell_dim_ + 4 * frame * cell_dim_;
  float *c_in        = c_data_bw + ((frame+1)%2) * cell_dim_;
  float* c_out;

  c_out       = c_data_bw + (frame%2)  * cell_dim_;

  if (c_in == NULL) {
    pw_vecMul_w(gridDim, blockDim, stream, in_gate, in_gate, in_gate2, cell_dim_);
    cudaErrCheck(cudaGetLastError());
  }
  else {              
    pw_vecMul_w(gridDim, blockDim, stream, forget_gate, forget_gate, c_in, cell_dim_);
    cudaErrCheck(cudaGetLastError());

    pw_vecMul_w(gridDim, blockDim, stream, in_gate, in_gate, in_gate2, cell_dim_);
    cudaErrCheck(cudaGetLastError());

    pw_vecAdd_w(gridDim, blockDim, stream, in_gate, in_gate, forget_gate, cell_dim_);
    cudaErrCheck(cudaGetLastError());
  }



  add_pw_vecMul_w(gridDim, blockDim, stream, out_gate, in_gate, phole_o_c_bw_ , cell_dim_);
  cudaErrCheck(cudaGetLastError());
  pw_sigmoid_w(gridDim, blockDim, stream, out_gate, out_gate, cell_dim_);
  cudaErrCheck(cudaGetLastError());
            //output gate

  if (c_out != NULL) {
  cudaErrCheck(cudaMemcpyAsync(c_out, in_gate, cell_dim_ * sizeof(float), cudaMemcpyDeviceToDevice, stream));
  }

  pw_tanh_w(gridDim, blockDim, stream, in_gate, in_gate, cell_dim_);
  cudaErrCheck(cudaGetLastError());

  pw_vecMul_w(gridDim, blockDim, stream, h_data_bw + (frame%2) * cell_dim_ , out_gate, in_gate, cell_dim_);
  cudaErrCheck(cudaGetLastError());
//error to check, I expect layer*(seqLength+1)*cell_dim_....see also gemm in which h_data is used, it requires also seqLength+1
         //compute M(t) and give it to next frame M(t-1)

  pw_vecMul_w(gridDim, blockDim, stream, out + cell_dim_ + frame * 2* cell_dim_, out_gate, in_gate, cell_dim_);
  cudaErrCheck(cudaGetLastError());

  }
/////////////////////////////frame loop
cudaEventRecord(stop);
cudaEventSynchronize(stop);
cudaEventElapsedTime(&elapsedTime, start, stop);
return elapsedTime;  

}
#endif


#if impl==2
  float Layer::Propagate(cublasHandle_t handle, float* in, float* out, int seqLength, float* tmp_h_fw, float* tmp_i_fw, float* tmp_h_bw, float* tmp_i_bw, float* h_data, float* c_data, float* h_data_bw, float* c_data_bw){
      //continue
  dim3 blockDim, gridDim;
  cudaStream_t stream=NULL;
  float alpha = 1.f;
  float beta  = 0.f;
  int frame;
  cudaEvent_t start, stop;
  float elapsedTime=0.f;
  
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord(start);

  const cublasOperation_t transa = CUBLAS_OP_N;
  const cublasOperation_t transb = CUBLAS_OP_N;
  cudaMemset(h_data, 0, cell_dim_*sizeof(float));
  cudaMemset(c_data, 0, cell_dim_*sizeof(float));
  cudaMemset(h_data_bw , 0, cell_dim_*sizeof(float));
  cudaMemset(c_data_bw , 0, cell_dim_*sizeof(float));

  
  
  cublasErrCheck(cublasSgemm(handle,
                        transa, transb,
                        4 * cell_dim_, //m, number of rows of matrix op(A) and C.
                        seqLength , //n, number of cols of matrix op(B) and C.
                        input_dim_,  //k, number of cols of matrix op(A) and rows of op(B).
                        &alpha,
                        wei_gifo_x_fw_,
                        transa == CUBLAS_OP_N ? 4 * cell_dim_ : input_dim_,  //leading dimension = number of rows (I use the number of col because I do the transpose with transa)
                        in,
                        input_dim_,
                        &beta,
                        tmp_i_fw,
                        4 * cell_dim_));
  cublasErrCheck(cublasSgemm(handle,
                        transa, transb,
                        4 * cell_dim_, //m, number of rows of matrix op(A) and C.
                        seqLength , //n, number of cols of matrix op(B) and C.
                        input_dim_,  //k, number of cols of matrix op(A) and rows of op(B).
                        &alpha,
                        wei_gifo_x_bw_,
                        transa == CUBLAS_OP_N ? 4*cell_dim_ : input_dim_,  //leading dimension = number of rows (I use the number of col because I do the transpose with transa)
                        in,
                        input_dim_,
                        &beta,
                        tmp_i_bw,
                        4 * cell_dim_));
  
  for (frame=0; frame < seqLength ; frame ++){
    stream=NULL;
    blockDim.x = 64;
    gridDim.x = (4*cell_dim_ + blockDim.x - 1) / blockDim.x;
    
    matvecfuse_w(gridDim, blockDim, stream, wei_gifo_m_fw_, h_data + (frame%2) * cell_dim_, tmp_i_fw + 4 * frame * cell_dim_, phole_i_c_fw_, phole_f_c_fw_, phole_o_c_fw_,  c_data + (frame%2) * cell_dim_, c_data + ((frame + 1)%2) * cell_dim_, h_data + ((frame + 1)%2) * cell_dim_, out + frame * 2* cell_dim_, 4*cell_dim_, cell_dim_);

	matvecfuse_w(gridDim, blockDim, stream, wei_gifo_m_fw_, h_data + (frame%2) * cell_dim_, tmp_i_fw + 4 * frame * cell_dim_, phole_i_c_fw_, phole_f_c_fw_, phole_o_c_fw_,  c_data + (frame%2) * cell_dim_, c_data + ((frame + 1)%2) * cell_dim_, h_data + ((frame + 1)%2) * cell_dim_, out + frame * 2* cell_dim_, 4*cell_dim_, cell_dim_);

  /*       cublasErrCheck(cublasSgemv(handle, transa,
               4 * cell_dim_, //m, number of rows of matrix op(A) 
               cell_dim_, //n, number of cols of matrix op(A).
               &alpha,
               wei_gifo_m_fw_, 
               4 * cell_dim_,
               h_data + (frame%2) * cell_dim_, 
               1, //stride input array
               &beta,
               tmp_h_fw, 
               1)); //stide output array
    
    
    elementWise_fp_w( gridDim, blockDim, stream, cell_dim_,tmp_h_fw, 
                       tmp_i_fw + 4 * frame * cell_dim_, 
                       bias_fw_,
                       phole_i_c_fw_,
                       phole_f_c_fw_,
                       phole_o_c_fw_,
                       h_data + ((frame + 1)%2) * cell_dim_,
                       out + frame * 2* cell_dim_,
                       c_data + (frame%2) * cell_dim_,
                       c_data + ((frame + 1)%2) * cell_dim_);*/
    }//frame loop

////backward//////////////////////////////////////////////////////////////////////
  //for (frame=seqLength-1; frame >=0 ; frame --){
  //  matvecfuse_w(gridDim, blockDim, stream, wei_gifo_m_bw_, h_data_bw + ((frame+1)%2) * cell_dim_, tmp_i_bw + 4 * frame * cell_dim_, phole_i_c_bw_, phole_f_c_bw_, phole_o_c_bw_,  c_data_bw + ((frame+1)%2) * cell_dim_, c_data_bw + (frame%2) * cell_dim_,  h_data_bw + (frame%2) * cell_dim_, out + frame * 2* cell_dim_+cell_dim_, 4*cell_dim_, cell_dim_);

      /*   cublasErrCheck(cublasSgemv(handle, transa,
               4*cell_dim_, //m, number of rows of matrix op(A) 
               cell_dim_, //n, number of cols of matrix op(A).
               &alpha,
               wei_gifo_m_bw_, 
               4*cell_dim_,
               h_data_bw + ((frame+1)%2) * cell_dim_, 
               1, //stride input array
               &beta,
               tmp_h_bw, 
               1)); //stide output array
    cudaStream_t stream=NULL;
    blockDim.x = 128;
    gridDim.x = (cell_dim_ + blockDim.x - 1) / blockDim.x;
    
    elementWise_fp_w( gridDim, blockDim, stream, cell_dim_,tmp_h_bw, 
                       tmp_i_bw + 4 * frame * cell_dim_, 
                       bias_bw_,
                       phole_i_c_bw_,
                       phole_f_c_bw_,
                       phole_o_c_bw_,
                       h_data_bw + (frame%2) * cell_dim_,
                       out + frame * 2* cell_dim_ + cell_dim_,
                       c_data_bw + ((frame+1)%2) * cell_dim_,
                       c_data_bw + (frame%2) * cell_dim_);*/
 // }
/////////////////////////////frame loop
cudaEventRecord(stop);
cudaEventSynchronize(stop);
cudaEventElapsedTime(&elapsedTime, start, stop);
return elapsedTime;  
}
#endif  



  void Layer::Init() {


  float mean = 0.0;
  float stdev = 1.0;
 
  curandGenerator_t rng;
  curandErrCheck(curandCreateGenerator(&rng, CURAND_RNG_PSEUDO_DEFAULT));
  curandErrCheck(curandSetPseudoRandomGeneratorSeed(rng, 1337ull));
//malloc forward//////////////////////////////////////////////////////////////////////////////////

//curandErrCheck(curandGenerateNormal(rng, i_data_bw, (seqLength) * 2 * , mean, stdev));
//cudaMemset(i_data+hiddenSize, 0, hiddenSize*sizeof(float));
  curandErrCheck(curandGenerateNormal(rng, wei_gifo_x_fw_, input_dim_  * 4 * cell_dim_, mean, stdev));
  curandErrCheck(curandGenerateNormal(rng, wei_gifo_m_fw_,  cell_dim_  * 4 * cell_dim_, mean, stdev));
//cudaMemset(T+hiddenSize*hiddenSize, 0, hiddenSize*sizeof(float));
  curandErrCheck(curandGenerateNormal(rng, bias_fw_, 4 * cell_dim_, mean, stdev));
  curandErrCheck(curandGenerateNormal(rng, phole_o_c_fw_, cell_dim_, mean, stdev));
  curandErrCheck(curandGenerateNormal(rng, phole_f_c_fw_, cell_dim_, mean, stdev));
  curandErrCheck(curandGenerateNormal(rng, phole_i_c_fw_, cell_dim_, mean, stdev));

  curandErrCheck(curandGenerateNormal(rng, wei_gifo_x_bw_, input_dim_  * 4 * cell_dim_, mean, stdev));
  curandErrCheck(curandGenerateNormal(rng, wei_gifo_m_bw_,  cell_dim_  * 4 * cell_dim_, mean, stdev));
//cudaMemset(T+hiddenSize*hiddenSize, 0, hiddenSize*sizeof(float));
  curandErrCheck(curandGenerateNormal(rng, bias_bw_, 4 * cell_dim_, mean, stdev));
  curandErrCheck(curandGenerateNormal(rng, phole_o_c_bw_, cell_dim_, mean, stdev));
  curandErrCheck(curandGenerateNormal(rng, phole_f_c_bw_, cell_dim_, mean, stdev));
  curandErrCheck(curandGenerateNormal(rng, phole_i_c_bw_, cell_dim_, mean, stdev));

////////////////////////////////////////////////////////////////////////////////////////////////
  curandErrCheck(curandDestroyGenerator(rng));

  // initialize layer
  }

